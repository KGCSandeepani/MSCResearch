{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "individual model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Method name  C20  C3  C4  C1  C5  C6  \\\n",
      "0  org.apache.camel.api.management.mbean.CamelOpe...    1   4   0   4   2   2   \n",
      "1  org.apache.camel.api.management.mbean.CamelOpe...    3   7   0   7   1   5   \n",
      "2  org.apache.camel.api.management.mbean.CamelOpe...    4   6   0   6   1   4   \n",
      "3  org.apache.camel.api.management.mbean.CamelOpe...    1   4   0   4   2   2   \n",
      "4  org.apache.camel.api.management.mbean.CamelOpe...    6   6   0   6   1   4   \n",
      "\n",
      "   C2  C21  C18  ...  H4  H1  H2  H3       H12  H13  H14  H15  H5  \\\n",
      "0   0    3    1  ...   4   4   0   4  1.000000  0.0  0.0  1.0   1   \n",
      "1   0    2    1  ...   8   8   0   8  1.142857  0.0  0.0  1.0   1   \n",
      "2   0    2    1  ...   2   1   0   1  0.166667  0.0  0.0  0.5   1   \n",
      "3   0    3    1  ...   1   1   0   1  0.250000  0.0  0.0  1.0   1   \n",
      "4   0    2    1  ...   3   3   0   3  0.500000  0.0  0.0  1.0   1   \n",
      "\n",
      "       bug-prone  \n",
      "0  not bug-prone  \n",
      "1  not bug-prone  \n",
      "2  not bug-prone  \n",
      "3  not bug-prone  \n",
      "4  not bug-prone  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import pandas libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# data = pd.read_csv(\"Data/activemq_result.csv\", delimiter=',')\n",
    "data = pd.read_csv(\"Data/camel_result.csv\", delimiter=',')\n",
    "\n",
    "\n",
    "# Explore the dataset\n",
    "print(data.head()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data\n",
    "data_transform = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Method name  C20  C3  C4  C1  C5  C6  \\\n",
      "0  org.apache.camel.api.management.mbean.CamelOpe...    1   4   0   4   2   2   \n",
      "1  org.apache.camel.api.management.mbean.CamelOpe...    3   7   0   7   1   5   \n",
      "2  org.apache.camel.api.management.mbean.CamelOpe...    4   6   0   6   1   4   \n",
      "3  org.apache.camel.api.management.mbean.CamelOpe...    1   4   0   4   2   2   \n",
      "4  org.apache.camel.api.management.mbean.CamelOpe...    6   6   0   6   1   4   \n",
      "\n",
      "   C2  C21  C18  ...  H4  H1  H2  H3       H12  H13  H14  H15  H5  bug-prone  \n",
      "0   0    3    1  ...   4   4   0   4  1.000000  0.0  0.0  1.0   1          0  \n",
      "1   0    2    1  ...   8   8   0   8  1.142857  0.0  0.0  1.0   1          0  \n",
      "2   0    2    1  ...   2   1   0   1  0.166667  0.0  0.0  0.5   1          0  \n",
      "3   0    3    1  ...   1   1   0   1  0.250000  0.0  0.0  1.0   1          0  \n",
      "4   0    2    1  ...   3   3   0   3  0.500000  0.0  0.0  1.0   1          0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'bug-prone' column to 0 and 1\n",
    "data_transform['bug-prone'] = data_transform['bug-prone'].apply(lambda x: 1 if x.strip() == 'bug-prone' else 0)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data_transform.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12081, 42)\n"
     ]
    }
   ],
   "source": [
    "print(data_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split feature data and target data\n",
    "feature_X = data_transform.drop(columns=['Method name','bug-prone'])\n",
    "y = data_transform['bug-prone']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTETomek first (on original feature space)\n",
    "smote = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(feature_X, y)\n",
    "\n",
    "# Apply StandardScaler after resampling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled\n",
    "y = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, f1_score, \n",
    "    matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "\n",
    "# Define custom scorers for cross-validation\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='binary'),  # For binary classification\n",
    "    'recall': make_scorer(recall_score, average='binary'),\n",
    "    'f1': make_scorer(f1_score, average='binary'),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'auc': make_scorer(roc_auc_score) # , needs_proba=True\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=5, \n",
    "                                       min_samples_leaf=2, class_weight='balanced', random_state=42)\n",
    "ada_classifier = AdaBoostClassifier(n_estimators=100, learning_rate=0.8, random_state=42)\n",
    "bagging_classifier = BaggingClassifier(n_estimators=100, max_samples=0.8, random_state=42)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan')\n",
    "mlp_classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(200,100), max_iter=2000, \n",
    "                            learning_rate='adaptive', random_state=42)\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "hgb_classifier = HistGradientBoostingClassifier(random_state=42)  \n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)  # max_depth=10, min_samples_split=10, min_samples_leaf=5,\n",
    "svm_classifier = SVC(random_state=42, probability=True, C=10, kernel='poly', gamma='scale')\n",
    "gnb_classifier = GaussianNB(var_smoothing=1e-9)\n",
    "lr_classifier = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "xgb_classifier = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "cb_classifier = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=4, verbose=0, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to display results\n",
    "def print_cv_results(results):\n",
    "    for metric in scoring.keys():\n",
    "        mean = results[f'test_{metric}'].mean()\n",
    "        std = results[f'test_{metric}'].std()\n",
    "        print(f\"{metric.capitalize()}: {mean:.4f} ± {std:.4f}\")\n",
    "\n",
    "def crossvalidate_fun(classifier, X_train, y_train):\n",
    "    cv_results = cross_validate(classifier, X_train, y_train, cv=10, scoring=scoring)\n",
    "    print_cv_results(cv_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(rf_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(ada_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(bagging_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(knn_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(mlp_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(gb_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidate_fun(hgb_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8650 ± 0.0612\n",
      "Precision: 0.8549 ± 0.0380\n",
      "Recall: 0.8767 ± 0.1113\n",
      "F1: 0.8632 ± 0.0726\n",
      "Mcc: 0.7340 ± 0.1196\n",
      "Auc: 0.8650 ± 0.0612\n"
     ]
    }
   ],
   "source": [
    "# crossvalidate_fun(dt_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7794 ± 0.0426\n",
      "Precision: 0.7417 ± 0.0408\n",
      "Recall: 0.8592 ± 0.0426\n",
      "F1: 0.7958 ± 0.0387\n",
      "Mcc: 0.5665 ± 0.0850\n",
      "Auc: 0.7794 ± 0.0426\n"
     ]
    }
   ],
   "source": [
    "# crossvalidate_fun(svm_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6324 ± 0.0180\n",
      "Precision: 0.8266 ± 0.0551\n",
      "Recall: 0.3374 ± 0.0242\n",
      "F1: 0.4783 ± 0.0268\n",
      "Mcc: 0.3293 ± 0.0470\n",
      "Auc: 0.6324 ± 0.0180\n"
     ]
    }
   ],
   "source": [
    "# crossvalidate_fun(gnb_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8025 ± 0.0502\n",
      "Precision: 0.8486 ± 0.0413\n",
      "Recall: 0.7338 ± 0.0794\n",
      "F1: 0.7860 ± 0.0633\n",
      "Mcc: 0.6111 ± 0.0966\n",
      "Auc: 0.8025 ± 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "crossvalidate_fun(lr_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8596 ± 0.0681\n",
      "Precision: 0.8716 ± 0.0318\n",
      "Recall: 0.8392 ± 0.1293\n",
      "F1: 0.8513 ± 0.0869\n",
      "Mcc: 0.7235 ± 0.1284\n",
      "Auc: 0.8596 ± 0.0681\n"
     ]
    }
   ],
   "source": [
    "# crossvalidate_fun(xgb_classifier,X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8547 ± 0.0661\n",
      "Precision: 0.8695 ± 0.0370\n",
      "Recall: 0.8306 ± 0.1198\n",
      "F1: 0.8466 ± 0.0828\n",
      "Mcc: 0.7130 ± 0.1257\n",
      "Auc: 0.8547 ± 0.0661\n"
     ]
    }
   ],
   "source": [
    "# crossvalidate_fun(cb_classifier,X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
